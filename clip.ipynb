{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23185,"status":"ok","timestamp":1681611923834,"user":{"displayName":"Xiao Wei","userId":"08626233611672043411"},"user_tz":240},"id":"gpvFK0dMuV01","outputId":"2ff2755a-08bf-4d79-cbf9-a4e5e2e5ee23"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","['label', 'train_images', 'model_weights.pt', 'image_embedding_VGG_finetuned.pt', 'memotion_train.csv', 'enhanced_train_images', 'compressed_train_images', 'model_weights_enhanced.pt', 'image_embedding_VGG_finetuned_enhanced.pt', 'model_weights_compressed.pt', 'val_images', 'Test Images', 'val_embedding_VGG_finetuned.pt', 'test_embedding_VGG_finetuned.pt', 'val_embedding_pretrained.pt', 'test_embedding_pretrained.pt', 'train_embedding_pretrained.pt', 'clip_embedding.pt']\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import sys\n","\n","# TODO: change this to the path to your homework folder\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '487/Project/'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","os.chdir(GOOGLE_DRIVE_PATH)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26008,"status":"ok","timestamp":1681611989336,"user":{"displayName":"Xiao Wei","userId":"08626233611672043411"},"user_tz":240},"id":"v687a6BtubYM","outputId":"a1672814-bbb2-4137-de1a-426ed7b5a0df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0-\u003etorch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0-\u003etorch) (16.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2-\u003etorch) (2.1.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision) (2.0.12)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision) (1.26.15)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision) (3.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision) (2022.12.7)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy-\u003etorch) (1.3.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-wemonrdc\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-wemonrdc\n","  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (2022.10.31)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (4.65.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from clip==1.0) (0.15.1+cu118)\n","Requirement already satisfied: wcwidth\u003e=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy-\u003eclip==1.0) (0.2.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch-\u003eclip==1.0) (4.5.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch-\u003eclip==1.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-\u003eclip==1.0) (3.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch-\u003eclip==1.0) (3.11.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch-\u003eclip==1.0) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch-\u003eclip==1.0) (1.11.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0-\u003etorch-\u003eclip==1.0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0-\u003etorch-\u003eclip==1.0) (16.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision-\u003eclip==1.0) (2.27.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision-\u003eclip==1.0) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision-\u003eclip==1.0) (8.4.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2-\u003etorch-\u003eclip==1.0) (2.1.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision-\u003eclip==1.0) (3.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision-\u003eclip==1.0) (2022.12.7)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision-\u003eclip==1.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision-\u003eclip==1.0) (2.0.12)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy-\u003etorch-\u003eclip==1.0) (1.3.0)\n","Building wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369398 sha256=a197ab5bf1d695c1860e7280abff714e4ff5c4dcfe1c9e582df3a83865b6a76d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7uplwzoo/wheels/c8/e4/e1/11374c111387672fc2068dfbe0d4b424cb9cdd1b2e184a71b5\n","Successfully built clip\n","Installing collected packages: ftfy, clip\n","Successfully installed clip-1.0 ftfy-6.1.1\n"]},{"name":"stderr","output_type":"stream","text":["100%|████████████████████████████████████████| 338M/338M [00:01\u003c00:00, 293MiB/s]\n"]}],"source":["!pip install torch torchvision\n","!pip install git+https://github.com/openai/CLIP.git\n","\n","import torch\n","import clip\n","from PIL import Image\n","import pandas as pd\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1356,"status":"ok","timestamp":1681612041245,"user":{"displayName":"Xiao Wei","userId":"08626233611672043411"},"user_tz":240},"id":"N1Hu99evvg5S"},"outputs":[],"source":["df = pd.read_csv('memotion_val.csv')\n","strings = df['ocr_text'].astype(str).tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"V5Nl7Xutuoz2"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","100\n","200\n","300\n","400\n","500\n","600\n","700\n","800\n","900\n","1000\n","1100\n","1200\n","1300\n","1400\n"]}],"source":["embed = ()\n","m_len = 75\n","for i in range(1500):\n","  if i % 100 == 0:\n","    print(i)\n","  # Load the image and preprocess it\n","  image = Image.open(f\"val_images/{i+1}.jpg\")\n","  image_input = preprocess(image).unsqueeze(0).to(device)\n","\n","  # Encode the text input\n","  chunks = [strings[i][i:i+m_len] for i in range(0, len(strings[i]), m_len)]\n","  chunks = [clip.tokenize(chunk) for chunk in chunks]\n","  chunks = torch.stack(chunks)\n","  chunks = torch.mean(chunks.float(), dim=0)\n","  text = chunks.to(torch.int).to(device)\n","\n","  # Get the embeddings\n","  with torch.no_grad():\n","    image_features = model.encode_image(image_input)\n","    text_features = model.encode_text(text)\n","    # Concatenate the image and text features\n","    features = torch.cat((image_features, text_features), dim=1)\n","\n","  embed = embed + (features,)\n","\n","embed = torch.stack(embed)\n","torch.save(embed.squeeze(), 'clip_embedding_val.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119,"status":"ok","timestamp":1681595990296,"user":{"displayName":"Xiao Wei","userId":"08626233611672043411"},"user_tz":240},"id":"ogyE4Sol7mY0","outputId":"4db8c97b-4c31-4aa2-8be6-e9f7bcf46a89"},"outputs":[{"data":{"text/plain":["torch.Size([7000, 1, 1024])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["embed.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OHe3P5z7pVN"},"outputs":[],"source":["torch.save(embed.squeeze(), 'clip_embedding.pt')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMHsKigWH8ugcGxi6QA4S5H","name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}